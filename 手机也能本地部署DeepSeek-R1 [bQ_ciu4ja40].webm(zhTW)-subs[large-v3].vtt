WEBVTT

00:00.000 --> 00:03.320
使用DeepSync R1不一定非要通過官方的App

00:03.320 --> 00:05.120
在本地運行也可以

00:05.120 --> 00:06.660
甚至在手機上

00:06.660 --> 00:08.960
我手裡這臺是iPhone 12 mini

00:08.960 --> 00:10.500
已經老的不能再老了

00:10.500 --> 00:12.540
一直是我的主力機我沒捨得換

00:12.540 --> 00:15.100
結果它居然也能跑R1

00:15.100 --> 00:16.380
這讓我非常的驚訝

00:16.380 --> 00:19.460
我用的是PokePal AI這款免費的App

00:19.460 --> 00:21.240
之前在社群裡有推薦過

00:21.240 --> 00:24.320
下載的是1.5B Q4精度的模型文件

00:24.320 --> 00:25.860
生成挺流暢的

00:25.860 --> 00:28.420
你看跟官方App裡的表現一樣

00:28.420 --> 00:30.460
先是給出思考的過程

00:30.460 --> 00:32.260
然後再給出結果

00:32.260 --> 00:34.300
在Benchmark頁面進行測試

00:34.300 --> 00:36.360
可以看到詳細的數值情況

00:36.360 --> 00:38.660
每秒大概有20個Token

00:38.660 --> 00:41.740
分值內存的佔用大概是33%

00:41.740 --> 00:43.260
如果是新一年的iPhone

00:43.260 --> 00:46.340
那麼可以去下載更高的精度獲得更好的效果

00:46.340 --> 00:49.160
比如我用我手裡這臺iPhone 14做了測試

00:49.160 --> 00:51.460
它最高可以跑Q8的精度

00:51.460 --> 00:53.260
每秒輸出16個Token

00:53.260 --> 00:54.540
再高就沒反應了

00:54.540 --> 00:56.320
比如FP16

00:56.320 --> 00:57.100
說實話

00:57.100 --> 00:58.380
比起DeepSync R1 1.5

00:58.380 --> 01:01.700
我個人會更喜歡千萬2.5 1.5B

01:01.700 --> 01:02.740
R1的思考過程

01:02.740 --> 01:04.260
我覺得有點太囉嗦了

01:04.260 --> 01:07.340
而且最終的結果也不見得會有質的提升

01:07.340 --> 01:08.100
Anyway

01:08.100 --> 01:10.920
大家根據自己的情況和偏好去選擇就好

01:10.920 --> 01:15.020
今天還不存在某一個模型會顯著超過其他所有的模型

01:15.020 --> 01:18.100
而且我覺得好的模型對你也不一定適用

01:18.100 --> 01:18.860
另外

01:18.860 --> 01:20.660
我知道這個視頻發出去之後

01:20.660 --> 01:23.980
肯定又會有人在質疑本地部署的必要性

01:23.980 --> 01:26.540
每次我發這類視頻都會被噴

01:26.540 --> 01:28.340
所以在這邊我統一回復一下

01:28.380 --> 01:30.180
老網友應該有印象

01:30.180 --> 01:31.700
在很多很多年以前

01:31.700 --> 01:33.500
谷歌推出了Chromebook

01:33.500 --> 01:35.040
這是一個上網本

01:35.040 --> 01:38.100
它的辦公軟件都是雲端的辦公套件

01:38.100 --> 01:39.140
谷歌全家桶

01:39.140 --> 01:40.660
按照那些人的邏輯

01:40.660 --> 01:41.940
那這樣就夠了呀

01:41.940 --> 01:44.260
為什麼還有本地版的Office全家桶呢

01:44.260 --> 01:45.020
結果

01:45.020 --> 01:47.060
市場給出了最終的選擇

01:47.060 --> 01:49.880
那AI在端測的落地也是一樣的

01:49.880 --> 01:51.940
如果都依賴雲端的算力

01:51.940 --> 01:53.720
AI絕對不可能普及

01:53.720 --> 01:54.500
比如

01:54.500 --> 01:55.520
需要網絡揭露

01:55.520 --> 01:57.560
用的人多了可能還要排隊

01:57.560 --> 01:58.340
還有莫名其妙

01:58.340 --> 02:00.640
的降制和懶惰的情況

02:00.640 --> 02:03.720
這些都會去極大的限制我們使用AI

02:03.720 --> 02:06.540
此外還有隱私和數據安全的問題

02:06.540 --> 02:08.320
所以依靠端測的算力

02:08.320 --> 02:11.660
在移動端去運行1.5B或者3B的模型

02:11.660 --> 02:14.720
在桌面端去跑7B或者14B的模型

02:14.720 --> 02:17.800
一定是未來一兩年的發展趨勢

02:17.800 --> 02:20.100
對想成為超級個體的人來說

02:20.100 --> 02:23.180
擁有更多的算力就能跑更強大的模型

02:23.180 --> 02:26.240
那知道每一種設備使用AI的方法

02:26.240 --> 02:28.040
就能更自由的去接入AI

02:28.040 --> 02:28.300
使用AI

02:28.300 --> 02:28.320
就能更自由的去接入AI使用AI

02:28.320 --> 02:28.840
使用AI

02:28.840 --> 02:30.620
那這些全部組合在一起

02:30.620 --> 02:32.680
就能讓你在那些普通人面前

02:32.680 --> 02:35.480
獲得一種unfair advantage

02:35.480 --> 02:36.260
哈嘍大家好

02:36.260 --> 02:37.540
歡迎來到我的頻道

02:37.540 --> 02:38.820
謙虛的說啊

02:38.820 --> 02:40.100
我是國內少數幾個

02:40.100 --> 02:42.920
能把關於AI的歪和好講明白的博主

02:42.920 --> 02:45.480
我提供的東西遠比教程更值錢

02:45.480 --> 02:47.000
記得點一波關注

02:47.000 --> 02:49.560
如果想鏈接我就來我們Newtype社群

02:49.560 --> 02:52.380
已經有800多位小夥伴付費加入啦

02:52.380 --> 02:53.920
回到今天的主題

02:53.920 --> 02:56.480
在端測部署DeepSeek R1

02:56.480 --> 02:58.280
過年這段時間我發現特別的熱鬧

02:58.280 --> 02:58.800
我發現特別的熱鬧

02:58.800 --> 03:00.580
年前先是川普發幣

03:00.580 --> 03:02.120
看起來很不合理

03:02.120 --> 03:04.420
但仔細想想好像也沒啥毛病

03:04.420 --> 03:06.980
人家要干涉一切發個幣算什麼

03:06.980 --> 03:09.540
這一波過去沒多久DeepSeek就來了

03:09.540 --> 03:11.080
鬧了一整個假期

03:11.080 --> 03:12.620
我的觀點很簡單

03:12.620 --> 03:15.440
這對所有人來說都是重大利好

03:15.440 --> 03:17.740
第一一款免費且開源

03:17.740 --> 03:19.780
支持深度思考和聯網搜索

03:19.780 --> 03:22.080
具備最強中文能力的模型

03:22.080 --> 03:24.640
能讓國內更多的普通人用上AI

03:24.640 --> 03:27.980
我在朋友圈裡看到好多之前基本不用AI的小夥伴

03:27.980 --> 03:29.780
這次都用DeepSeek了

03:29.780 --> 03:31.560
前幾天跟親戚聚餐

03:31.560 --> 03:34.380
有一位阿姨居然也主動了解了DeepSeek

03:34.380 --> 03:35.920
還向我安利他們的APP

03:35.920 --> 03:38.220
非要我去下載體驗一下

03:38.220 --> 03:40.020
反正能普及AI

03:40.020 --> 03:41.540
就是功德無量的事

03:41.540 --> 03:42.060
第二

03:42.060 --> 03:43.340
R1推出之後

03:43.340 --> 03:45.140
業內都在各種反思

03:45.140 --> 03:48.460
比如之前對算力的使用是不是過於粗犯了

03:48.460 --> 03:49.220
等等

03:49.220 --> 03:52.300
同時也給那些幣源的廠商更強的緊迫感

03:52.300 --> 03:53.580
比如OpenAI

03:53.580 --> 03:56.140
讓他們去抓緊推出新的模型和產品

03:56.140 --> 03:56.660
你看

03:56.660 --> 03:57.940
OSAN Mini這不就來了嗎

03:57.940 --> 03:57.960
你看OSAN Mini這不就來了嗎

03:57.980 --> 04:00.020
我相信經過這一波

04:00.020 --> 04:02.340
各家的模型廠商都會有所得

04:02.340 --> 04:05.140
這個就是開源開放權重的意義

04:05.140 --> 04:07.700
之前某些人說開源只是置山稅

04:07.700 --> 04:09.760
開源模型只會越來越落後

04:09.760 --> 04:12.060
現在看來是不是特別的可笑

04:12.060 --> 04:12.580
第三

04:12.580 --> 04:13.860
對於投資者來說

04:13.860 --> 04:15.900
這一波既是賣出英偉達的機會

04:15.900 --> 04:17.940
也是買入英偉達的機會

04:17.940 --> 04:20.500
在大跌的那一天我就開始買入了

04:20.500 --> 04:21.280
邏輯很簡單

04:21.280 --> 04:23.060
我在社群內也發過

04:23.060 --> 04:25.620
DeepSeek的方法如果是可scalable的

04:25.620 --> 04:27.940
那麼買卡還得繼續

04:27.940 --> 04:28.960
大家要知道

04:28.960 --> 04:31.520
他們並不是從零到一發現了一條新的

04:31.520 --> 04:33.320
不同於scaling load的道路

04:33.320 --> 04:35.360
其實還是原先的大方向

04:35.360 --> 04:37.920
而且也不存在什麼不需要CUDA

04:37.920 --> 04:38.940
不需要高算力

04:38.940 --> 04:41.500
不需要GPU改用ASIC的情況

04:41.500 --> 04:43.560
這全都是那些外行不懂專懂

04:43.560 --> 04:45.860
為了流量去哄你們玩的

04:45.860 --> 04:48.940
各家公司還是會想方設法的去買卡

04:48.940 --> 04:50.460
比如從新加坡走

04:50.460 --> 04:52.780
所以這一波的下跌只是一時的恐慌

04:52.780 --> 04:54.560
以及之前漲了那麼多

04:54.560 --> 04:56.860
市場普遍預期是要回調

04:56.860 --> 04:57.900
等待新的故事

04:57.900 --> 05:00.980
所以大家都不約而同去演了這麼一出

05:00.980 --> 05:03.540
普羅大眾開心了揚眉吐氣了

05:03.540 --> 05:06.100
資本落袋為安了開始觀望了

05:06.100 --> 05:09.160
美國政府也有理由要求嚴加管控了

05:09.160 --> 05:11.220
每個人都各取所需

05:11.220 --> 05:12.740
我們都有美好的未來

05:12.740 --> 05:14.540
我還是堅定認為

05:14.540 --> 05:16.340
在AI這件事情上邊

05:16.340 --> 05:18.120
不存在彎道超車

05:18.120 --> 05:21.700
咱們中國人特別擅長做從一到一百的事情

05:21.700 --> 05:25.300
這一點在之前的互聯網和移動互聯網時代特別的明顯

05:25.300 --> 05:27.860
因為從零到一的基礎研發

05:27.900 --> 05:29.940
人家都完成了也分享出來了

05:29.940 --> 05:32.500
然後我們跟上去做應用落地

05:32.500 --> 05:34.300
你再看中國的那些VC

05:34.300 --> 05:37.880
有哪一家敢真的去投從零到一的項目

05:37.880 --> 05:39.940
他們那些拿出來吹的成績單

05:39.940 --> 05:42.740
全都是對現成紅利的收割

05:42.740 --> 05:45.060
但是AI這一波不一樣了

05:45.060 --> 05:48.380
因為基礎研發和落地應用是齊頭並進的

05:48.380 --> 05:52.220
所以不去開拓只等著摘果子是肯定行不通的

05:52.220 --> 05:54.260
人家也不想當冤大頭啊

05:54.260 --> 05:57.600
DeepSeek和R1的其他AI公司有很大不同

05:57.600 --> 06:00.680
不管是錢還是人都很不太一樣

06:00.680 --> 06:02.980
這也許就是他們能成功的原因

06:02.980 --> 06:05.020
好了這個話題不能再多說了

06:05.020 --> 06:06.040
我要被噴了

06:06.040 --> 06:08.600
回頭我在社群裡發個視頻細說

06:08.600 --> 06:11.940
咱們還是回來聊端設部署DeepSeek R1

06:11.940 --> 06:13.720
大家日常使用的話

06:13.720 --> 06:15.000
如果是在桌面端

06:15.000 --> 06:19.100
那最簡單的方法肯定是通過我們的老朋友歐拉瑪

06:19.100 --> 06:21.660
來到歐拉瑪官網的DeepSeek R1頁面

06:21.660 --> 06:23.200
就會看到原始的模型

06:23.200 --> 06:26.020
以及蒸餾出來的六個小尺寸的模型

06:26.020 --> 06:27.040
從1.5B

06:27.040 --> 06:27.560
7B

06:27.560 --> 06:29.100
到70B都有

06:29.100 --> 06:33.700
我拿3060顯卡的PC和M4的Mac mini都測了一下

06:33.700 --> 06:35.240
3060跑7B

06:35.240 --> 06:36.780
每秒Token有46

06:36.780 --> 06:38.820
非常的絲滑順暢

06:38.820 --> 06:39.600
跑8B

06:39.600 --> 06:40.880
每秒Token有44

06:40.880 --> 06:41.900
差不多

06:41.900 --> 06:42.920
跑14B

06:42.920 --> 06:45.740
速度降到26也完全能接受

06:45.740 --> 06:49.320
注意這個是我在開著OBS錄屏的情況下的數據

06:49.320 --> 06:50.600
如果沒開的話

06:50.600 --> 06:53.160
每秒的Token數量會多個四五個

06:53.160 --> 06:55.460
再來看M4 Mac mini的情況

06:55.460 --> 06:57.520
我這個是24G的統一內存

06:57.520 --> 06:59.820
跑7B每秒Token有19

06:59.820 --> 07:01.880
跑8B每秒Token17

07:01.880 --> 07:02.900
跑14B

07:02.900 --> 07:04.940
每秒Token就只剩10了

07:04.940 --> 07:05.720
看起來

07:05.720 --> 07:07.760
Mac mini的主要優勢是功耗

07:07.760 --> 07:09.300
如果你追求性能的話

07:09.300 --> 07:10.580
還得是PC

07:10.580 --> 07:13.140
當模型跑起來之後要進行對話

07:13.140 --> 07:15.180
可選的App就很多了

07:15.180 --> 07:16.980
如果你不需要那麼多的功能

07:16.980 --> 07:18.520
就是想清爽一點的話

07:18.520 --> 07:20.560
可以用Enchanted

07:20.560 --> 07:22.600
如果你還有RAG之類的需求

07:22.600 --> 07:24.660
那可以用Anything LLM

07:24.660 --> 07:26.960
去年我推薦過它好多次

07:26.960 --> 07:28.500
它安裝起來很方便

07:28.500 --> 07:29.780
不需要通過Docker

07:29.780 --> 07:32.340
Docker真的會勸退很多人

07:32.340 --> 07:33.560
此外Lobchat

07:33.560 --> 07:35.160
TypingMate等等這些產品

07:35.160 --> 07:36.940
都支持去接入OLAMA

07:36.940 --> 07:39.760
這個方面的應用已經非常非常豐富了

07:39.760 --> 07:41.800
大家可以隨意去挑選

07:41.800 --> 07:43.860
那要在移動端去使用的話

07:43.860 --> 07:45.140
7B肯定跑不動

07:45.140 --> 07:47.700
只能選擇1.5B的尺寸

07:47.700 --> 07:49.480
至於運行模型需要的App

07:49.480 --> 07:50.760
選擇也不少

07:50.760 --> 07:52.820
比如我之前花錢買了這個

07:52.820 --> 07:53.840
它的好處是

07:53.840 --> 07:55.380
除了支持本地運行之外

07:55.380 --> 07:56.920
還可以連接Open Router

07:56.960 --> 07:58.760
或者你自己的服務器

07:58.760 --> 08:00.540
但是它的缺點是

08:00.540 --> 08:02.840
支持的開源模型太少太少了

08:02.840 --> 08:05.160
只有列表裡的這一點點

08:05.160 --> 08:07.720
所以我最終選擇了PokePal AI

08:07.720 --> 08:10.520
它支持從Hugging Face下載模型文件

08:10.520 --> 08:11.800
這種感覺怎麼說呢

08:11.800 --> 08:14.120
就像是連接上了汪洋大海

08:14.120 --> 08:15.140
打開App

08:15.140 --> 08:16.920
點擊右下角的加號按鈕

08:16.920 --> 08:19.480
這時你可以選擇從本地加載

08:19.480 --> 08:21.800
也就是你已經下載好的模型文件

08:21.800 --> 08:23.840
或者去Hugging Face下載

08:23.840 --> 08:26.400
我這邊選擇從Hugging Face下載

08:26.400 --> 08:28.440
那在輸入框裡輸入幾個關鍵詞

08:28.440 --> 08:30.760
就能找到你想要的模型

08:30.760 --> 08:32.280
之後的使用就很簡單了

08:32.280 --> 08:34.080
加載模型開始對話

08:34.080 --> 08:35.620
唯一需要注意的地方是

08:35.620 --> 08:38.680
在設置裡把上下文長度調高一些

08:38.680 --> 08:40.480
不然可能只有思考的過程

08:40.480 --> 08:42.280
給不出最終的結果

08:42.280 --> 08:44.580
今天的開源模型發展非常非常快

08:44.580 --> 08:47.140
新的模型一般都有全尺寸的覆蓋

08:47.140 --> 08:48.420
比如阿里的千問

08:48.420 --> 08:50.200
2.5包含7個尺寸

08:50.200 --> 08:52.260
VL也就是視覺模型版本

08:52.260 --> 08:53.800
也有3B的版本

08:53.800 --> 08:56.100
想象一下過個半年到一年

08:56.100 --> 08:58.140
還是手機能跑的小尺寸

08:58.140 --> 08:59.420
模型性能更強

08:59.420 --> 09:00.700
多模態更成熟

09:00.700 --> 09:01.740
到那個時候

09:01.740 --> 09:04.540
你就理解本地部署的好處和必要性了

09:04.540 --> 09:06.600
OK以上就是本期內容

09:06.600 --> 09:08.900
想進一步討論AI就來我們Newtype社群

09:08.900 --> 09:09.660
我都在

09:09.660 --> 09:10.940
那咱們下期見

