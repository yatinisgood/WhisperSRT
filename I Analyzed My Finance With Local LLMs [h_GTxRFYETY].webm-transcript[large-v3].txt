 as i get older i realize money is not everything but it's kind of almost everything so every year or every other year i download all my bank transactions and review my incomes and expenses the other day i came across someone who made this income and expense breakdown and i feel really inspired to do the same usually the most tricky thing in the process is to classify the expenses from my buying transactions into appropriate categories a lot of times i just use my manual labor or some low-tech ways to do that this year i decided to ask chat to pt to crunch the number for me and maybe tell me when i can retire only then to realize that i can't just upload my bank statement to chat tbt website it's all sensitive information about places i've been to shops i visited how much i spent on buying secret items and other personal data although using open ai apis may help still the data sent via the api is stored by openai for a duration of up to 30 days so eventually i decided to download and run an open source large language model locally on my laptop and the best thing yet they are free in this project video we do a few exciting things first we learn to install and run an lm for example llama 2 locally on our laptop then we use the lm to classify all the expenses in my bank statement into categories such as groceries rent travel and so on we then analyze the data in python and create some visualizations to show the main insights i shared all the codes on github so you can check out the github repo in the video description this video is sponsored by coursera coursera is running a discount with 200 off the coursera plus annual subscription if you sign up this is half the regular price for the whole year with this subscription you can get access to the course you can also use the course you can also use the course you can also use the course course you can also use the course you can also use the course you can also use the course you can also use to tons of courses and certificates in data analytics, including the Google Data Analytics and the Google Advanced Data Analytics Certificates. These certificates teach you all the fundamentals you need as a beginner in data analytics. So check out the offer below. There are a few different ways to run a large language model locally on your laptop, which means you can run the LLM without internet connection, without a third-party service like an API service or a website like ChatGPT. As you can imagine, this is secure if you want to protect your personal data, and it's free. There are now a few different frameworks developed to help us run an open-source language model locally on our own device. Some popular frameworks are LLM-CPP, GPT-4-0, and OLAMA. So you might be wondering, why the heck do we even need these frameworks? Remember how large language models are trained? They're basically the result of taking a huge amount of internet data and train a large neural network on it. And the model that comes out is basically a zip file with a bunch of numbers that represents the weights of all the parameters in the neural network. This model file can be quite large, depending on how many parameters the model has. So frameworks like OLAMA and LLAMA-CPP basically try to do two things. The first thing is quantization. It tries to reduce the memory footprint of the raw model weights. And the second thing is it makes it more efficient to run an open-source language model locally on your device. So if you have a Mac or Linux machine, I'd highly recommend installing OLAMA. It's super simple, and I'll show you in a bit. If you have a Windows machine, you can also run OLAMA through the Docker desktop. Okay, now let's go to OLAMA website. And here you can download OLAMA, which is available for Mac OS and Linux, and Windows will be coming soon. Also have a quick look at the list of models that are available. So here we have LLAMA 2, Maestro, we have a bunch of other code models. And so there's a lot of options here for you to try out. And if we click on any of them, we can see the description, also how to use API, what is the memory requirements, so how much RAM you need in your laptop in order to run these models. So let's download OLAMA and install it. It's very straightforward, just like installing any app on your laptop. So once we've installed OLAMA, we can start using it through our terminal. In order to do a language model locally through OLAMA, we just need to run the command OLAMAPOOL and then specify the model that you want to install. So for example, I will install again Maestro. It's pretty fast because I've already installed it last time. So and you can see here the model is around 4GB. So in order to use a model through a terminal, we just need to do OLAMA run Maestro. And here we can start typing our message or our prompt. So let's say hello, and the model replied with Hello, how can I help you today? Oh, so that's a lot of things. Okay, so I can ask something a little bit stupid. What's 2 plus 2? Okay, it comes back with quite an elaborate answer. Now, let's try another question. I want to see if it actually can do math properly. Let me ask what's this times this. Okay, wow, that's amazing. Okay, it even tries to teach me how to find the product of two large numbers so let me go to Google. Okay, so what I have here is around 426 billion. However, if I look at the result here, it's actually not correct. 45 million. You can check this result using a calculator to make sure it's correct. Well, I've checked it and it's not correct. I kind of have to say I'm impressed. But in terms of basic arithmetic, I think large language models out of the box are not probably not the best option. All right, the next thing we want to test, that is very important for this project, is whether the Maestro model can properly classify all the different expenses in my bank statement into different categories. So I just try out a prompt here to see how it performs. Now, I ask, can you add an appropriate category to the following expenses? For example, Spotify as entertainment, beta photos as sports, and here I just give a list of transactions as shown in my bank statement. So let's see what it comes up with. Okay, so it replies with three categories. It's roughly correct. I would say it's reasonable, but it missed one transaction here, which is Bistro Bar Amsterdam. And also, it doesn't really reply in the format that I wanted. So the transaction together with the category separate by this hyphen. So I feel like Maestro, it doesn't really do the task as I expected it to do. So let's try Lama2. Let's exit this model and we will Olama run Lama2. But if you haven't installed Lama2, you can do Olamapool Lama2 and the Lama2 model will be installed locally in your computer. Now, we can start using Lama2 model. Now, let's ask the same question as we asked before. And it does it pretty well. It gives me a list of the expenses together with the categories. Although, the first two are my own example, but it does give me the correct format for the answers and so each of these transactions has a category added next to it separated by a hyphen so i'm pretty happy with llama2 and it actually understands the task although if you keep asking the same question to these language models multiple times these models may come back with different answers each time and so there's definitely a certain level of randomness in the responses if you want to take a step further to customize these language models to your specific use case you can do that by specifying a model file and a model file is basically the blueprint to create and share language models with olama so you can specify the base model you want to use and also you can set parameters like the temperature for the model now let's go back to the terminal and exit this model let's clear the terminal and i'll go ahead and create a model file with nano and i'll name this model file as expense analyzer and we'll go into the text editor okay let's first specify the base model as llama2 so from llama2 and next we'll set the temperature parameter as let's say 0.8 temperature closer to 1 is more creative and the lower the temperature the more coherent and less creative the model behaves and further let's also specify the custom system message so my system prompt is quite basic if you're a financial assistant you have classified expense and income from buying transactions okay let's save this file by ctrl x yes enter now that we have the model file set up we can use this model file to create a custom model we can do this by olama create we specify the custom model name dash f and then specify the name of the model file so that is pens analyzer so now if we run this comment basically what it's doing is that olama will pass through this text file this model file expands analyzer passing through all the parameters and the custom message that we put in and then customize all these different layers in the base model which is lama2 and now we can start using this custom lama2 model that we just created by olama run expense analyzer i also forgot to mention that we can also now uh look at the model list available by olama list and you can also muito les take a look at the model list available by olama list and you can also also find out the base model that we allì—” used to make custom models also see that now we have the expense analyzer llama2 model available in our list now interacting with these local elements through the terminal is also fine but i find a more convenient way to interact with these models is through the python environment and more specifically through jupyter notebook now let's create a project folder and i'll move my bank transaction data in inside this folder and i'll just start up visual studio code from this folder in order to access these language models from olama with python we need to install the langchaincommunity library and so if you haven't done so we can use pip install and now we can access all the language models we have installed through olama by specifying the name of the model with this olama method for example the first man on the moon was dot dot dot and after a few seconds we get back the completion of this sentence so that means our model is up and running that is a good sign now let's move on to reading that milky way of thinking so that means our model is up and running that is a good sign now let's move on to reading that austin will 19606 now let's move on to reading that austin will 19606 transaction data that we have and take a look at it you can see that here in the name description column we have all the transactions that we want to classify we have the indicator whether it is expense or income and we also have the amount in euros of these transactions now i have anonymized a lot of these transactions so this is not my real income and real expenses now we need to find a way to insert all these different expenses into our prompt right let's get all the unique transactions from our data you can see that this is quite a big list and this may exceed the token limit that the large language model has so if we try to insert this huge list into our prompt there's a risk that the model comes back with a completely nonsensical answer or incomplete answer because your question is already taking too many tokens so after many trial and errors i found that around two and a half minutes or so we have a lot of questions that we can answer and we can't answer 30 transactions would give the most optimal response so here you can see an example response with 30 transactions so with this approach we are going to create a for loop to basically loop through all the 300 transactions here in our bank statement and we take in 30 transactions at a time and so a handy way to handle this for loop is to get an index list so this index list is basically giving us a sequence of all the index from zero until the last item hopping 30 items at a time and with this we can also conveniently handle the last group as well which might not be 30 items but maybe less now let's initialize a data frame to store all the unique transactions and their responding categories and with this for loop our call a custom function that i created and this function takes the names of the transactions or the lm that we are using and the only thing we need to do is to properly parse the output from the language model into a format that we can work with. So if we look at this output, we definitely only want to keep these lines, right? And we don't want the rest like certainly here's the categories. But we don't need to worry about this for now because at the end, we can always remove all the rows that have categories being none. The complication is that sometimes the language model might use a different format for the answer. So we had to use some kind of like validator for the output in order to make sure that the output actually is in the format we want. For example, in the response, we have the hyphen in between the transaction and the category. So one handy Python library for this is Pydantic. So the idea is that after getting the response, we will run it through a validation check. If the validation fails, we will rerun the language model to get another response until we get the right output. If you're interested in how to do this with Pydantic, you can click on the link in the description below. And if you're interested in the code in the GitHub repo, link in description. Okay, now let me run this for loop and also print out the transaction names and also the output by the models. I also noticed that when I'm running this for loop, for some reason, if I want to stop it, I really cannot stop it. So if for some reason we want to interrupt this process, we can go to the terminal and do pqolama. And so in the back end, all the olama processes will be stopped. Okay, after a while, if everything goes well, we should get back the data frame. Okay, so now we're done with all the transactions with the categories that Lama2 has categorized for us. I'll just save the CSV here. Now let's open the CSV file and quickly look at the output. Overall, I'm quite happy with the categories that Lama2 came up with. However, some categories may be quite similar to each other, but not completely the same. And I want to group them together. So I just quickly group these categories by hand. Now the last step is to clean up a little bit this data frame. And then we can go ahead and merge this data frame. And then we can go ahead and my data frame into the main transaction data frame using the transaction name. So after this, we should have a data frame with all information, the transactions and the categories. So that was exciting. But the next part of the project is even more exciting. We create a personal finance dashboard based on the transaction data that we just obtained. The idea for this dashboard is we want to show the income breakdown and the expense breakdown for both years 2022 and 2023. And at the bottom i also want to show how much i earn and how much i spend per month in each year so for creating interactive visualization i love using plotly express for the creation of the dashboard we also use panel panel is an awesome library for creating data dashboard very easily and very fast now let's read in our transaction data and for the income i don't have a lot of income sources so i can just use the name of the income as the category firstly we want to make the pie chart to show the income and expense breakdown i create a function here to basically take the data and select for the year and whether we are looking at the expense or the income in the data set and similarly i also create a function to make bar charts that basically gives us a histogram of the income or expense per month over the year and you can see that it's super nice with plotly express that you can also hover on the different sections on the graph and see the data label now we're almost done we just need to combine and organize all these charts on our dashboard so here just create a panel layout with the tabs which consists of two tabs we have the 2022 for 2023 tab we have exactly the same charts and graphs but for 2023 data and to show all this nicely on the dashboard we will use a template from our dashboard which is called fastlist template we can specify the header of our dashboard we have the sidebar which is some information and also you can put in different elements or pictures etc and in the main here we will put in the tabs that we just created and if we do template show we can see that this is our dashboard and here's my income and expense breakdown and here is how much i earned and how much i spent per month in each year you can see that i do a little bit more in 2022 than in 2023 which is not really a good sign but if you're into personal finance and things like that you may notice that this overview is probably not complete because we also have assets so if you transfer your money to an investment account or if you pay the mortgage towards your house then part of that money is also your asset as well and not only your expense although as you can see i can't retire anytime soon i hope this inspires you to do your own projects and experiment with open source language models i think in the future it will be a norm for us to be able to use and run large language models locally on laptops and other personal devices if you enjoyed this project also check out other data science projects on my channel thank you for watching bye