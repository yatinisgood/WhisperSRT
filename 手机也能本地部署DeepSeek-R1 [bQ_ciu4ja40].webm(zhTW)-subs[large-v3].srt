1
00:00:00,000 --> 00:00:03,320
使用DeepSync R1不一定非要通過官方的App

2
00:00:03,320 --> 00:00:05,120
在本地運行也可以

3
00:00:05,120 --> 00:00:06,660
甚至在手機上

4
00:00:06,660 --> 00:00:08,960
我手裡這臺是iPhone 12 mini

5
00:00:08,960 --> 00:00:10,500
已經老的不能再老了

6
00:00:10,500 --> 00:00:12,540
一直是我的主力機我沒捨得換

7
00:00:12,540 --> 00:00:15,100
結果它居然也能跑R1

8
00:00:15,100 --> 00:00:16,380
這讓我非常的驚訝

9
00:00:16,380 --> 00:00:19,460
我用的是PokePal AI這款免費的App

10
00:00:19,460 --> 00:00:21,240
之前在社群裡有推薦過

11
00:00:21,240 --> 00:00:24,320
下載的是1.5B Q4精度的模型文件

12
00:00:24,320 --> 00:00:25,860
生成挺流暢的

13
00:00:25,860 --> 00:00:28,420
你看跟官方App裡的表現一樣

14
00:00:28,420 --> 00:00:30,460
先是給出思考的過程

15
00:00:30,460 --> 00:00:32,260
然後再給出結果

16
00:00:32,260 --> 00:00:34,300
在Benchmark頁面進行測試

17
00:00:34,300 --> 00:00:36,360
可以看到詳細的數值情況

18
00:00:36,360 --> 00:00:38,660
每秒大概有20個Token

19
00:00:38,660 --> 00:00:41,740
分值內存的佔用大概是33%

20
00:00:41,740 --> 00:00:43,260
如果是新一年的iPhone

21
00:00:43,260 --> 00:00:46,340
那麼可以去下載更高的精度獲得更好的效果

22
00:00:46,340 --> 00:00:49,160
比如我用我手裡這臺iPhone 14做了測試

23
00:00:49,160 --> 00:00:51,460
它最高可以跑Q8的精度

24
00:00:51,460 --> 00:00:53,260
每秒輸出16個Token

25
00:00:53,260 --> 00:00:54,540
再高就沒反應了

26
00:00:54,540 --> 00:00:56,320
比如FP16

27
00:00:56,320 --> 00:00:57,100
說實話

28
00:00:57,100 --> 00:00:58,380
比起DeepSync R1 1.5

29
00:00:58,380 --> 00:01:01,700
我個人會更喜歡千萬2.5 1.5B

30
00:01:01,700 --> 00:01:02,740
R1的思考過程

31
00:01:02,740 --> 00:01:04,260
我覺得有點太囉嗦了

32
00:01:04,260 --> 00:01:07,340
而且最終的結果也不見得會有質的提升

33
00:01:07,340 --> 00:01:08,100
Anyway

34
00:01:08,100 --> 00:01:10,920
大家根據自己的情況和偏好去選擇就好

35
00:01:10,920 --> 00:01:15,020
今天還不存在某一個模型會顯著超過其他所有的模型

36
00:01:15,020 --> 00:01:18,100
而且我覺得好的模型對你也不一定適用

37
00:01:18,100 --> 00:01:18,860
另外

38
00:01:18,860 --> 00:01:20,660
我知道這個視頻發出去之後

39
00:01:20,660 --> 00:01:23,980
肯定又會有人在質疑本地部署的必要性

40
00:01:23,980 --> 00:01:26,540
每次我發這類視頻都會被噴

41
00:01:26,540 --> 00:01:28,340
所以在這邊我統一回復一下

42
00:01:28,380 --> 00:01:30,180
老網友應該有印象

43
00:01:30,180 --> 00:01:31,700
在很多很多年以前

44
00:01:31,700 --> 00:01:33,500
谷歌推出了Chromebook

45
00:01:33,500 --> 00:01:35,040
這是一個上網本

46
00:01:35,040 --> 00:01:38,100
它的辦公軟件都是雲端的辦公套件

47
00:01:38,100 --> 00:01:39,140
谷歌全家桶

48
00:01:39,140 --> 00:01:40,660
按照那些人的邏輯

49
00:01:40,660 --> 00:01:41,940
那這樣就夠了呀

50
00:01:41,940 --> 00:01:44,260
為什麼還有本地版的Office全家桶呢

51
00:01:44,260 --> 00:01:45,020
結果

52
00:01:45,020 --> 00:01:47,060
市場給出了最終的選擇

53
00:01:47,060 --> 00:01:49,880
那AI在端測的落地也是一樣的

54
00:01:49,880 --> 00:01:51,940
如果都依賴雲端的算力

55
00:01:51,940 --> 00:01:53,720
AI絕對不可能普及

56
00:01:53,720 --> 00:01:54,500
比如

57
00:01:54,500 --> 00:01:55,520
需要網絡揭露

58
00:01:55,520 --> 00:01:57,560
用的人多了可能還要排隊

59
00:01:57,560 --> 00:01:58,340
還有莫名其妙

60
00:01:58,340 --> 00:02:00,640
的降制和懶惰的情況

61
00:02:00,640 --> 00:02:03,720
這些都會去極大的限制我們使用AI

62
00:02:03,720 --> 00:02:06,540
此外還有隱私和數據安全的問題

63
00:02:06,540 --> 00:02:08,320
所以依靠端測的算力

64
00:02:08,320 --> 00:02:11,660
在移動端去運行1.5B或者3B的模型

65
00:02:11,660 --> 00:02:14,720
在桌面端去跑7B或者14B的模型

66
00:02:14,720 --> 00:02:17,800
一定是未來一兩年的發展趨勢

67
00:02:17,800 --> 00:02:20,100
對想成為超級個體的人來說

68
00:02:20,100 --> 00:02:23,180
擁有更多的算力就能跑更強大的模型

69
00:02:23,180 --> 00:02:26,240
那知道每一種設備使用AI的方法

70
00:02:26,240 --> 00:02:28,040
就能更自由的去接入AI

71
00:02:28,040 --> 00:02:28,300
使用AI

72
00:02:28,300 --> 00:02:28,320
就能更自由的去接入AI使用AI

73
00:02:28,320 --> 00:02:28,840
使用AI

74
00:02:28,840 --> 00:02:30,620
那這些全部組合在一起

75
00:02:30,620 --> 00:02:32,680
就能讓你在那些普通人面前

76
00:02:32,680 --> 00:02:35,480
獲得一種unfair advantage

77
00:02:35,480 --> 00:02:36,260
哈嘍大家好

78
00:02:36,260 --> 00:02:37,540
歡迎來到我的頻道

79
00:02:37,540 --> 00:02:38,820
謙虛的說啊

80
00:02:38,820 --> 00:02:40,100
我是國內少數幾個

81
00:02:40,100 --> 00:02:42,920
能把關於AI的歪和好講明白的博主

82
00:02:42,920 --> 00:02:45,480
我提供的東西遠比教程更值錢

83
00:02:45,480 --> 00:02:47,000
記得點一波關注

84
00:02:47,000 --> 00:02:49,560
如果想鏈接我就來我們Newtype社群

85
00:02:49,560 --> 00:02:52,380
已經有800多位小夥伴付費加入啦

86
00:02:52,380 --> 00:02:53,920
回到今天的主題

87
00:02:53,920 --> 00:02:56,480
在端測部署DeepSeek R1

88
00:02:56,480 --> 00:02:58,280
過年這段時間我發現特別的熱鬧

89
00:02:58,280 --> 00:02:58,800
我發現特別的熱鬧

90
00:02:58,800 --> 00:03:00,580
年前先是川普發幣

91
00:03:00,580 --> 00:03:02,120
看起來很不合理

92
00:03:02,120 --> 00:03:04,420
但仔細想想好像也沒啥毛病

93
00:03:04,420 --> 00:03:06,980
人家要干涉一切發個幣算什麼

94
00:03:06,980 --> 00:03:09,540
這一波過去沒多久DeepSeek就來了

95
00:03:09,540 --> 00:03:11,080
鬧了一整個假期

96
00:03:11,080 --> 00:03:12,620
我的觀點很簡單

97
00:03:12,620 --> 00:03:15,440
這對所有人來說都是重大利好

98
00:03:15,440 --> 00:03:17,740
第一一款免費且開源

99
00:03:17,740 --> 00:03:19,780
支持深度思考和聯網搜索

100
00:03:19,780 --> 00:03:22,080
具備最強中文能力的模型

101
00:03:22,080 --> 00:03:24,640
能讓國內更多的普通人用上AI

102
00:03:24,640 --> 00:03:27,980
我在朋友圈裡看到好多之前基本不用AI的小夥伴

103
00:03:27,980 --> 00:03:29,780
這次都用DeepSeek了

104
00:03:29,780 --> 00:03:31,560
前幾天跟親戚聚餐

105
00:03:31,560 --> 00:03:34,380
有一位阿姨居然也主動了解了DeepSeek

106
00:03:34,380 --> 00:03:35,920
還向我安利他們的APP

107
00:03:35,920 --> 00:03:38,220
非要我去下載體驗一下

108
00:03:38,220 --> 00:03:40,020
反正能普及AI

109
00:03:40,020 --> 00:03:41,540
就是功德無量的事

110
00:03:41,540 --> 00:03:42,060
第二

111
00:03:42,060 --> 00:03:43,340
R1推出之後

112
00:03:43,340 --> 00:03:45,140
業內都在各種反思

113
00:03:45,140 --> 00:03:48,460
比如之前對算力的使用是不是過於粗犯了

114
00:03:48,460 --> 00:03:49,220
等等

115
00:03:49,220 --> 00:03:52,300
同時也給那些幣源的廠商更強的緊迫感

116
00:03:52,300 --> 00:03:53,580
比如OpenAI

117
00:03:53,580 --> 00:03:56,140
讓他們去抓緊推出新的模型和產品

118
00:03:56,140 --> 00:03:56,660
你看

119
00:03:56,660 --> 00:03:57,940
OSAN Mini這不就來了嗎

120
00:03:57,940 --> 00:03:57,960
你看OSAN Mini這不就來了嗎

121
00:03:57,980 --> 00:04:00,020
我相信經過這一波

122
00:04:00,020 --> 00:04:02,340
各家的模型廠商都會有所得

123
00:04:02,340 --> 00:04:05,140
這個就是開源開放權重的意義

124
00:04:05,140 --> 00:04:07,700
之前某些人說開源只是置山稅

125
00:04:07,700 --> 00:04:09,760
開源模型只會越來越落後

126
00:04:09,760 --> 00:04:12,060
現在看來是不是特別的可笑

127
00:04:12,060 --> 00:04:12,580
第三

128
00:04:12,580 --> 00:04:13,860
對於投資者來說

129
00:04:13,860 --> 00:04:15,900
這一波既是賣出英偉達的機會

130
00:04:15,900 --> 00:04:17,940
也是買入英偉達的機會

131
00:04:17,940 --> 00:04:20,500
在大跌的那一天我就開始買入了

132
00:04:20,500 --> 00:04:21,280
邏輯很簡單

133
00:04:21,280 --> 00:04:23,060
我在社群內也發過

134
00:04:23,060 --> 00:04:25,620
DeepSeek的方法如果是可scalable的

135
00:04:25,620 --> 00:04:27,940
那麼買卡還得繼續

136
00:04:27,940 --> 00:04:28,960
大家要知道

137
00:04:28,960 --> 00:04:31,520
他們並不是從零到一發現了一條新的

138
00:04:31,520 --> 00:04:33,320
不同於scaling load的道路

139
00:04:33,320 --> 00:04:35,360
其實還是原先的大方向

140
00:04:35,360 --> 00:04:37,920
而且也不存在什麼不需要CUDA

141
00:04:37,920 --> 00:04:38,940
不需要高算力

142
00:04:38,940 --> 00:04:41,500
不需要GPU改用ASIC的情況

143
00:04:41,500 --> 00:04:43,560
這全都是那些外行不懂專懂

144
00:04:43,560 --> 00:04:45,860
為了流量去哄你們玩的

145
00:04:45,860 --> 00:04:48,940
各家公司還是會想方設法的去買卡

146
00:04:48,940 --> 00:04:50,460
比如從新加坡走

147
00:04:50,460 --> 00:04:52,780
所以這一波的下跌只是一時的恐慌

148
00:04:52,780 --> 00:04:54,560
以及之前漲了那麼多

149
00:04:54,560 --> 00:04:56,860
市場普遍預期是要回調

150
00:04:56,860 --> 00:04:57,900
等待新的故事

151
00:04:57,900 --> 00:05:00,980
所以大家都不約而同去演了這麼一出

152
00:05:00,980 --> 00:05:03,540
普羅大眾開心了揚眉吐氣了

153
00:05:03,540 --> 00:05:06,100
資本落袋為安了開始觀望了

154
00:05:06,100 --> 00:05:09,160
美國政府也有理由要求嚴加管控了

155
00:05:09,160 --> 00:05:11,220
每個人都各取所需

156
00:05:11,220 --> 00:05:12,740
我們都有美好的未來

157
00:05:12,740 --> 00:05:14,540
我還是堅定認為

158
00:05:14,540 --> 00:05:16,340
在AI這件事情上邊

159
00:05:16,340 --> 00:05:18,120
不存在彎道超車

160
00:05:18,120 --> 00:05:21,700
咱們中國人特別擅長做從一到一百的事情

161
00:05:21,700 --> 00:05:25,300
這一點在之前的互聯網和移動互聯網時代特別的明顯

162
00:05:25,300 --> 00:05:27,860
因為從零到一的基礎研發

163
00:05:27,900 --> 00:05:29,940
人家都完成了也分享出來了

164
00:05:29,940 --> 00:05:32,500
然後我們跟上去做應用落地

165
00:05:32,500 --> 00:05:34,300
你再看中國的那些VC

166
00:05:34,300 --> 00:05:37,880
有哪一家敢真的去投從零到一的項目

167
00:05:37,880 --> 00:05:39,940
他們那些拿出來吹的成績單

168
00:05:39,940 --> 00:05:42,740
全都是對現成紅利的收割

169
00:05:42,740 --> 00:05:45,060
但是AI這一波不一樣了

170
00:05:45,060 --> 00:05:48,380
因為基礎研發和落地應用是齊頭並進的

171
00:05:48,380 --> 00:05:52,220
所以不去開拓只等著摘果子是肯定行不通的

172
00:05:52,220 --> 00:05:54,260
人家也不想當冤大頭啊

173
00:05:54,260 --> 00:05:57,600
DeepSeek和R1的其他AI公司有很大不同

174
00:05:57,600 --> 00:06:00,680
不管是錢還是人都很不太一樣

175
00:06:00,680 --> 00:06:02,980
這也許就是他們能成功的原因

176
00:06:02,980 --> 00:06:05,020
好了這個話題不能再多說了

177
00:06:05,020 --> 00:06:06,040
我要被噴了

178
00:06:06,040 --> 00:06:08,600
回頭我在社群裡發個視頻細說

179
00:06:08,600 --> 00:06:11,940
咱們還是回來聊端設部署DeepSeek R1

180
00:06:11,940 --> 00:06:13,720
大家日常使用的話

181
00:06:13,720 --> 00:06:15,000
如果是在桌面端

182
00:06:15,000 --> 00:06:19,100
那最簡單的方法肯定是通過我們的老朋友歐拉瑪

183
00:06:19,100 --> 00:06:21,660
來到歐拉瑪官網的DeepSeek R1頁面

184
00:06:21,660 --> 00:06:23,200
就會看到原始的模型

185
00:06:23,200 --> 00:06:26,020
以及蒸餾出來的六個小尺寸的模型

186
00:06:26,020 --> 00:06:27,040
從1.5B

187
00:06:27,040 --> 00:06:27,560
7B

188
00:06:27,560 --> 00:06:29,100
到70B都有

189
00:06:29,100 --> 00:06:33,700
我拿3060顯卡的PC和M4的Mac mini都測了一下

190
00:06:33,700 --> 00:06:35,240
3060跑7B

191
00:06:35,240 --> 00:06:36,780
每秒Token有46

192
00:06:36,780 --> 00:06:38,820
非常的絲滑順暢

193
00:06:38,820 --> 00:06:39,600
跑8B

194
00:06:39,600 --> 00:06:40,880
每秒Token有44

195
00:06:40,880 --> 00:06:41,900
差不多

196
00:06:41,900 --> 00:06:42,920
跑14B

197
00:06:42,920 --> 00:06:45,740
速度降到26也完全能接受

198
00:06:45,740 --> 00:06:49,320
注意這個是我在開著OBS錄屏的情況下的數據

199
00:06:49,320 --> 00:06:50,600
如果沒開的話

200
00:06:50,600 --> 00:06:53,160
每秒的Token數量會多個四五個

201
00:06:53,160 --> 00:06:55,460
再來看M4 Mac mini的情況

202
00:06:55,460 --> 00:06:57,520
我這個是24G的統一內存

203
00:06:57,520 --> 00:06:59,820
跑7B每秒Token有19

204
00:06:59,820 --> 00:07:01,880
跑8B每秒Token17

205
00:07:01,880 --> 00:07:02,900
跑14B

206
00:07:02,900 --> 00:07:04,940
每秒Token就只剩10了

207
00:07:04,940 --> 00:07:05,720
看起來

208
00:07:05,720 --> 00:07:07,760
Mac mini的主要優勢是功耗

209
00:07:07,760 --> 00:07:09,300
如果你追求性能的話

210
00:07:09,300 --> 00:07:10,580
還得是PC

211
00:07:10,580 --> 00:07:13,140
當模型跑起來之後要進行對話

212
00:07:13,140 --> 00:07:15,180
可選的App就很多了

213
00:07:15,180 --> 00:07:16,980
如果你不需要那麼多的功能

214
00:07:16,980 --> 00:07:18,520
就是想清爽一點的話

215
00:07:18,520 --> 00:07:20,560
可以用Enchanted

216
00:07:20,560 --> 00:07:22,600
如果你還有RAG之類的需求

217
00:07:22,600 --> 00:07:24,660
那可以用Anything LLM

218
00:07:24,660 --> 00:07:26,960
去年我推薦過它好多次

219
00:07:26,960 --> 00:07:28,500
它安裝起來很方便

220
00:07:28,500 --> 00:07:29,780
不需要通過Docker

221
00:07:29,780 --> 00:07:32,340
Docker真的會勸退很多人

222
00:07:32,340 --> 00:07:33,560
此外Lobchat

223
00:07:33,560 --> 00:07:35,160
TypingMate等等這些產品

224
00:07:35,160 --> 00:07:36,940
都支持去接入OLAMA

225
00:07:36,940 --> 00:07:39,760
這個方面的應用已經非常非常豐富了

226
00:07:39,760 --> 00:07:41,800
大家可以隨意去挑選

227
00:07:41,800 --> 00:07:43,860
那要在移動端去使用的話

228
00:07:43,860 --> 00:07:45,140
7B肯定跑不動

229
00:07:45,140 --> 00:07:47,700
只能選擇1.5B的尺寸

230
00:07:47,700 --> 00:07:49,480
至於運行模型需要的App

231
00:07:49,480 --> 00:07:50,760
選擇也不少

232
00:07:50,760 --> 00:07:52,820
比如我之前花錢買了這個

233
00:07:52,820 --> 00:07:53,840
它的好處是

234
00:07:53,840 --> 00:07:55,380
除了支持本地運行之外

235
00:07:55,380 --> 00:07:56,920
還可以連接Open Router

236
00:07:56,960 --> 00:07:58,760
或者你自己的服務器

237
00:07:58,760 --> 00:08:00,540
但是它的缺點是

238
00:08:00,540 --> 00:08:02,840
支持的開源模型太少太少了

239
00:08:02,840 --> 00:08:05,160
只有列表裡的這一點點

240
00:08:05,160 --> 00:08:07,720
所以我最終選擇了PokePal AI

241
00:08:07,720 --> 00:08:10,520
它支持從Hugging Face下載模型文件

242
00:08:10,520 --> 00:08:11,800
這種感覺怎麼說呢

243
00:08:11,800 --> 00:08:14,120
就像是連接上了汪洋大海

244
00:08:14,120 --> 00:08:15,140
打開App

245
00:08:15,140 --> 00:08:16,920
點擊右下角的加號按鈕

246
00:08:16,920 --> 00:08:19,480
這時你可以選擇從本地加載

247
00:08:19,480 --> 00:08:21,800
也就是你已經下載好的模型文件

248
00:08:21,800 --> 00:08:23,840
或者去Hugging Face下載

249
00:08:23,840 --> 00:08:26,400
我這邊選擇從Hugging Face下載

250
00:08:26,400 --> 00:08:28,440
那在輸入框裡輸入幾個關鍵詞

251
00:08:28,440 --> 00:08:30,760
就能找到你想要的模型

252
00:08:30,760 --> 00:08:32,280
之後的使用就很簡單了

253
00:08:32,280 --> 00:08:34,080
加載模型開始對話

254
00:08:34,080 --> 00:08:35,620
唯一需要注意的地方是

255
00:08:35,620 --> 00:08:38,680
在設置裡把上下文長度調高一些

256
00:08:38,680 --> 00:08:40,480
不然可能只有思考的過程

257
00:08:40,480 --> 00:08:42,280
給不出最終的結果

258
00:08:42,280 --> 00:08:44,580
今天的開源模型發展非常非常快

259
00:08:44,580 --> 00:08:47,140
新的模型一般都有全尺寸的覆蓋

260
00:08:47,140 --> 00:08:48,420
比如阿里的千問

261
00:08:48,420 --> 00:08:50,200
2.5包含7個尺寸

262
00:08:50,200 --> 00:08:52,260
VL也就是視覺模型版本

263
00:08:52,260 --> 00:08:53,800
也有3B的版本

264
00:08:53,800 --> 00:08:56,100
想象一下過個半年到一年

265
00:08:56,100 --> 00:08:58,140
還是手機能跑的小尺寸

266
00:08:58,140 --> 00:08:59,420
模型性能更強

267
00:08:59,420 --> 00:09:00,700
多模態更成熟

268
00:09:00,700 --> 00:09:01,740
到那個時候

269
00:09:01,740 --> 00:09:04,540
你就理解本地部署的好處和必要性了

270
00:09:04,540 --> 00:09:06,600
OK以上就是本期內容

271
00:09:06,600 --> 00:09:08,900
想進一步討論AI就來我們Newtype社群

272
00:09:08,900 --> 00:09:09,660
我都在

273
00:09:09,660 --> 00:09:10,940
那咱們下期見

