使用DeepSync R1不一定非要通过官方的App在本地运行也可以甚至在手机上我手里这台是iPhone 12 mini已经老的不能再老了一直是我的主力机我没舍得换结果它居然也能跑R1这让我非常的惊讶我用的是PokePal AI这款免费的App之前在社群里有推荐过下载的是1.5B Q4精度的模型文件生成挺流畅的你看跟官方App里的表现一样先是给出思考的过程然后再给出结果在Benchmark页面进行测试可以看到详细的数值情况每秒大概有20个Token分值内存的占用大概是33%如果是新一年的iPhone那么可以去下载更高的精度获得更好的效果比如我用我手里这台iPhone 14做了测试它最高可以跑Q8的精度每秒输出16个Token再高就没反应了比如FP16说实话比起DeepSync R1 1.5我个人会更喜欢千万2.5 1.5BR1的思考过程我觉得有点太啰嗦了而且最终的结果也不见得会有质的提升Anyway大家根据自己的情况和偏好去选择就好今天还不存在某一个模型会显著超过其他所有的模型而且我觉得好的模型对你也不一定适用另外我知道这个视频发出去之后肯定又会有人在质疑本地部署的必要性每次我发这类视频都会被喷所以在这边我统一回复一下老网友应该有印象在很多很多年以前谷歌推出了Chromebook这是一个上网本它的办公软件都是云端的办公套件谷歌全家桶按照那些人的逻辑那这样就够了呀为什么还有本地版的Office全家桶呢结果市场给出了最终的选择那AI在端测的落地也是一样的如果都依赖云端的算力AI绝对不可能普及比如需要网络揭露用的人多了可能还要排队还有莫名其妙的降制和懒惰的情况这些都会去极大的限制我们使用AI此外还有隐私和数据安全的问题所以依靠端测的算力在移动端去运行1.5B或者3B的模型在桌面端去跑7B或者14B的模型一定是未来一两年的发展趋势对想成为超级个体的人来说拥有更多的算力就能跑更强大的模型那知道每一种设备使用AI的方法就能更自由的去接入AI使用AI就能更自由的去接入AI使用AI使用AI那这些全部组合在一起就能让你在那些普通人面前获得一种unfair advantage哈喽大家好欢迎来到我的频道谦虚的说啊我是国内少数几个能把关于AI的歪和好讲明白的博主我提供的东西远比教程更值钱记得点一波关注如果想链接我就来我们Newtype社群已经有800多位小伙伴付费加入啦回到今天的主题在端测部署DeepSeek R1过年这段时间我发现特别的热闹我发现特别的热闹年前先是川普发币看起来很不合理但仔细想想好像也没啥毛病人家要干涉一切发个币算什么这一波过去没多久DeepSeek就来了闹了一整个假期我的观点很简单这对所有人来说都是重大利好第一一款免费且开源支持深度思考和联网搜索具备最强中文能力的模型能让国内更多的普通人用上AI我在朋友圈里看到好多之前基本不用AI的小伙伴这次都用DeepSeek了前几天跟亲戚聚餐有一位阿姨居然也主动了解了DeepSeek还向我安利他们的APP非要我去下载体验一下反正能普及AI就是功德无量的事第二R1推出之后业内都在各种反思比如之前对算力的使用是不是过于粗犯了等等同时也给那些币源的厂商更强的紧迫感比如OpenAI让他们去抓紧推出新的模型和产品你看OSAN Mini这不就来了吗你看OSAN Mini这不就来了吗我相信经过这一波各家的模型厂商都会有所得这个就是开源开放权重的意义之前某些人说开源只是置山税开源模型只会越来越落后现在看来是不是特别的可笑第三对于投资者来说这一波既是卖出英伟达的机会也是买入英伟达的机会在大跌的那一天我就开始买入了逻辑很简单我在社群内也发过DeepSeek的方法如果是可scalable的那么买卡还得继续大家要知道他们并不是从零到一发现了一条新的不同于scaling load的道路其实还是原先的大方向而且也不存在什么不需要CUDA不需要高算力不需要GPU改用ASIC的情况这全都是那些外行不懂专懂为了流量去哄你们玩的各家公司还是会想方设法的去买卡比如从新加坡走所以这一波的下跌只是一时的恐慌以及之前涨了那么多市场普遍预期是要回调等待新的故事所以大家都不约而同去演了这么一出普罗大众开心了扬眉吐气了资本落袋为安了开始观望了美国政府也有理由要求严加管控了每个人都各取所需我们都有美好的未来我还是坚定认为在AI这件事情上边不存在弯道超车咱们中国人特别擅长做从一到一百的事情这一点在之前的互联网和移动互联网时代特别的明显因为从零到一的基础研发人家都完成了也分享出来了然后我们跟上去做应用落地你再看中国的那些VC有哪一家敢真的去投从零到一的项目他们那些拿出来吹的成绩单全都是对现成红利的收割但是AI这一波不一样了因为基础研发和落地应用是齐头并进的所以不去开拓只等着摘果子是肯定行不通的人家也不想当冤大头啊DeepSeek和R1的其他AI公司有很大不同不管是钱还是人都很不太一样这也许就是他们能成功的原因好了这个话题不能再多说了我要被喷了回头我在社群里发个视频细说咱们还是回来聊端设部署DeepSeek R1大家日常使用的话如果是在桌面端那最简单的方法肯定是通过我们的老朋友欧拉玛来到欧拉玛官网的DeepSeek R1页面就会看到原始的模型以及蒸馏出来的六个小尺寸的模型从1.5B7B到70B都有我拿3060显卡的PC和M4的Mac mini都测了一下3060跑7B每秒Token有46非常的丝滑顺畅跑8B每秒Token有44差不多跑14B速度降到26也完全能接受注意这个是我在开着OBS录屏的情况下的数据如果没开的话每秒的Token数量会多个四五个再来看M4 Mac mini的情况我这个是24G的统一内存跑7B每秒Token有19跑8B每秒Token17跑14B每秒Token就只剩10了看起来Mac mini的主要优势是功耗如果你追求性能的话还得是PC当模型跑起来之后要进行对话可选的App就很多了如果你不需要那么多的功能就是想清爽一点的话可以用Enchanted如果你还有RAG之类的需求那可以用Anything LLM去年我推荐过它好多次它安装起来很方便不需要通过DockerDocker真的会劝退很多人此外LobchatTypingMate等等这些产品都支持去接入OLAMA这个方面的应用已经非常非常丰富了大家可以随意去挑选那要在移动端去使用的话7B肯定跑不动只能选择1.5B的尺寸至于运行模型需要的App选择也不少比如我之前花钱买了这个它的好处是除了支持本地运行之外还可以连接Open Router或者你自己的服务器但是它的缺点是支持的开源模型太少太少了只有列表里的这一点点所以我最终选择了PokePal AI它支持从Hugging Face下载模型文件这种感觉怎么说呢就像是连接上了汪洋大海打开App点击右下角的加号按钮这时你可以选择从本地加载也就是你已经下载好的模型文件或者去Hugging Face下载我这边选择从Hugging Face下载那在输入框里输入几个关键词就能找到你想要的模型之后的使用就很简单了加载模型开始对话唯一需要注意的地方是在设置里把上下文长度调高一些不然可能只有思考的过程给不出最终的结果今天的开源模型发展非常非常快新的模型一般都有全尺寸的覆盖比如阿里的千问2.5包含7个尺寸VL也就是视觉模型版本也有3B的版本想象一下过个半年到一年还是手机能跑的小尺寸模型性能更强多模态更成熟到那个时候你就理解本地部署的好处和必要性了OK以上就是本期内容想进一步讨论AI就来我们Newtype社群我都在那咱们下期见